{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42071963",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.cross_validation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2fac869da449>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_validation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.cross_validation'"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "\n",
    "\n",
    "dataset = pd.read_csv(\"phishcoop.csv\")\n",
    "dataset = dataset.drop('id', 1) #removing unwanted column\n",
    "\n",
    "x = dataset.iloc[ : , :-1].values\n",
    "y = dataset.iloc[:, -1:].values\n",
    "\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.25, random_state =0 )\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = [{'n_estimators': [100, 700],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'criterion' :['gini', 'entropy']}]\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(),  parameters,cv =5, n_jobs= -1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best Accurancy =\" +str( grid_search.best_score_))\n",
    "print(\"best parameters =\" + str(grid_search.best_params_)) \n",
    "\n",
    "\n",
    " \n",
    "classifier = RandomForestClassifier(n_estimators = 100, criterion = \"gini\", max_features = 'log2',  random_state = 0)\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(classifier, 'phish_trainedv3.sav')\n",
    "\n",
    "\n",
    "names = dataset.iloc[:,:-1].columns\n",
    "importances =classifier.feature_importances_\n",
    "sorted_importances = sorted(importances, reverse=True)\n",
    "indices = np.argsort(-importances)\n",
    "var_imp = pd.DataFrame(sorted_importances, names[indices], columns=['importance'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Variable Importances\")\n",
    "plt.barh(np.arange(len(names)), sorted_importances, height = 0.7)\n",
    "plt.yticks(np.arange(len(names)), names[indices], fontsize=7)\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543d1bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
